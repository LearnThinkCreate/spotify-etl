[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Spotify ETL",
    "section": "",
    "text": "I love music.\nSince 2014 I’ve listened to around 3 hours of music a day on Spotify. Hardly a day has gone by since I was 15 that I haven’t listened to any music.\nWhile sad I cried to music. While happy I danced to music. While angry I raged to music.\nMy spotify history isn’t just some random dataset I scraped online. It’s personal. Inside it are a thousand songs that tell my life story. I want to find a way to tell that story.\nLike many websites, Spotify provides users with access to their data. While it’s amazing this dataset exists, it’s not entirely useful in itself. See the dictionary below for a example record from 2017 \n\n\n{'ts': '2017-04-22T21:43:11Z',\n 'username': 1241589622,\n 'platform': 'iOS 10.2 (iPhone7,2)',\n 'ms_played': 183925,\n 'conn_country': 'US',\n 'ip_addr_decrypted': '174.227.14.87',\n 'user_agent_decrypted': 'unknown',\n 'master_metadata_track_name': 'Seen It All',\n 'master_metadata_album_artist_name': 'Jeezy',\n 'master_metadata_album_album_name': 'Seen It All: The Autobiography',\n 'spotify_track_uri': 'spotify:track:0jkeRqlWciqKxU3iHQfdWj',\n 'episode_name': None,\n 'episode_show_name': None,\n 'spotify_episode_uri': None,\n 'reason_start': 'clickrow',\n 'reason_end': 'fwdbtn',\n 'shuffle': False,\n 'skipped': nan,\n 'offline': False,\n 'offline_timestamp': 1492897206495,\n 'incognito_mode': False}\n\n\nAdmittedly, there are some cool tidbits here.\n1st off: I was listening to Jeezy at 10PM on a Saturday night, my senior year of high school… I don’t imagine I was up to much good.\nAdditionally I can see what phone I had at that time (cool), the reason I started, and ended, the track, and what album the song was from.\nThat’s all solid information but it has no depth. It doesn’t help me tell my story.\nIt’s missing crucial metadata about the song like its energy, genre, and release date. In order to find all this information another tool is required: the spotify api. The API has (most) of the information. See below \n\ntrack = sp.track(\"0jkeRqlWciqKxU3iHQfdWj\")\n{\n    k: track[k]\n    for k in [\"artists\", \"duration_ms\", \"explicit\", \"name\", \"popularity\", \"preview_url\"]\n}\n\n{'artists': [{'external_urls': {'spotify': 'https://open.spotify.com/artist/4yBK75WVCQXej1p04GWqxH'},\n   'href': 'https://api.spotify.com/v1/artists/4yBK75WVCQXej1p04GWqxH',\n   'id': '4yBK75WVCQXej1p04GWqxH',\n   'name': 'Jeezy',\n   'type': 'artist',\n   'uri': 'spotify:artist:4yBK75WVCQXej1p04GWqxH'},\n  {'external_urls': {'spotify': 'https://open.spotify.com/artist/3nFkdlSjzX9mRTtwJOzDYB'},\n   'href': 'https://api.spotify.com/v1/artists/3nFkdlSjzX9mRTtwJOzDYB',\n   'id': '3nFkdlSjzX9mRTtwJOzDYB',\n   'name': 'JAY-Z',\n   'type': 'artist',\n   'uri': 'spotify:artist:3nFkdlSjzX9mRTtwJOzDYB'}],\n 'duration_ms': 207533,\n 'explicit': True,\n 'name': 'Seen It All',\n 'popularity': 59,\n 'preview_url': None}\n\n\nWith the track endpoint we start to get some more information! We see that Jay-Z is also on the track, that it’s explicit (…), and how long the song is.\nWe can do better.\nLet’s take a look at the Audio Feature endpoint\n\nsp.audio_features(\"0jkeRqlWciqKxU3iHQfdWj\")\n\n[{'danceability': 0.711,\n  'energy': 0.833,\n  'key': 7,\n  'loudness': -4.818,\n  'mode': 1,\n  'speechiness': 0.154,\n  'acousticness': 0.135,\n  'instrumentalness': 0,\n  'liveness': 0.301,\n  'valence': 0.545,\n  'tempo': 106.094,\n  'type': 'audio_features',\n  'id': '0jkeRqlWciqKxU3iHQfdWj',\n  'uri': 'spotify:track:0jkeRqlWciqKxU3iHQfdWj',\n  'track_href': 'https://api.spotify.com/v1/tracks/0jkeRqlWciqKxU3iHQfdWj',\n  'analysis_url': 'https://api.spotify.com/v1/audio-analysis/0jkeRqlWciqKxU3iHQfdWj',\n  'duration_ms': 207533,\n  'time_signature': 4}]\n\n\nNow we’re cooking baby!\nNow we can start to quantify the songs I’m listening to. Seen It All is high energy (yeah it is), pretty danceable, and has a tempo of 106 BPM.\nWhat about the genre though?\nIn my opinion that’s one of the most important characteristics of a song and it turns out that spotify only provides genre metadata at the artist level :(\n\nsp.artist(\"4yBK75WVCQXej1p04GWqxH\")\n\n{'external_urls': {'spotify': 'https://open.spotify.com/artist/4yBK75WVCQXej1p04GWqxH'},\n 'followers': {'href': None, 'total': 2360020},\n 'genres': ['atl hip hop',\n  'crunk',\n  'dirty south rap',\n  'gangster rap',\n  'old school atlanta hip hop',\n  'rap',\n  'southern hip hop',\n  'trap'],\n 'href': 'https://api.spotify.com/v1/artists/4yBK75WVCQXej1p04GWqxH',\n 'id': '4yBK75WVCQXej1p04GWqxH',\n 'images': [{'height': 640,\n   'url': 'https://i.scdn.co/image/ab6761610000e5eb075a4c9d6da66addd8247c12',\n   'width': 640},\n  {'height': 320,\n   'url': 'https://i.scdn.co/image/ab67616100005174075a4c9d6da66addd8247c12',\n   'width': 320},\n  {'height': 160,\n   'url': 'https://i.scdn.co/image/ab6761610000f178075a4c9d6da66addd8247c12',\n   'width': 160}],\n 'name': 'Jeezy',\n 'popularity': 70,\n 'type': 'artist',\n 'uri': 'spotify:artist:4yBK75WVCQXej1p04GWqxH'}\n\n\nThroughout these notebooks I transform my original spotify data from a bunch of json files to database tables and a materialized view that enabled me to build a website.\nAnd I’m only getting started…",
    "crumbs": [
      "Spotify ETL"
    ]
  },
  {
    "objectID": "clean_data.html",
    "href": "clean_data.html",
    "title": "Clean History",
    "section": "",
    "text": "streaming_history = extract_streaming_history(Path(\"streaming_history\"))\nclean_history = clean_streaming_history(streaming_history, 0.7)\ntrack_metadata = get_pickle_data(Path(\"data/track_metadata.pkl\"))\nartist_metadata = get_pickle_data(Path(\"data/artist_metadata.pkl\"))\nalbum_metadata = get_pickle_data(Path(\"data/album_metadata.pkl\"))\naudio_features = get_pickle_data(Path(\"data/audio_features.pkl\"))\nraw_track_metadata = get_pickle_data(Path(\"data/raw_track_metadata.pkl\"))\nraw_artist_metadata = get_pickle_data(Path(\"data/raw_artist_metadata.pkl\"))\ndef dict_to_df(dict, index_name=\"\"):\n    return pd.DataFrame(dict).T.reset_index(names=[index_name])\ntrack_df = dict_to_df(track_metadata, \"track_id\")\nartist_df = dict_to_df(artist_metadata, \"artist_id\")\nalbum_df = dict_to_df(album_metadata, \"album_id\")\nraw_track_df = dict_to_df(raw_track_metadata, \"album_id\")",
    "crumbs": [
      "Clean History"
    ]
  },
  {
    "objectID": "clean_data.html#clean-track-data",
    "href": "clean_data.html#clean-track-data",
    "title": "Clean History",
    "section": "Clean Track Data",
    "text": "Clean Track Data\nremoving artist data from the track df\n\n\nCode\ntrack_df = (\n    track_df.drop(\n        [\n            \"artist\",\n            \"artist_genres\",\n            \"artist_main_genre\",\n            \"artist_secondary_genre\",\n            \"artist_image\",\n            \"main_artist_url\",\n            \"id\",\n            \"main_artist_uri\",\n        ],\n        axis=1,\n    )\n    .merge(\n        raw_track_df[[\"duration_ms\", \"explicit\", \"popularity\", \"id\"]].rename(\n            columns={\"id\": \"track_id\"}\n        ),\n        on=\"track_id\",\n        how=\"left\",\n    )\n    .rename(\n        columns={\n            \"name\": \"song\",\n            \"artist_id\": \"main_artist_id\",\n            \"popularity\": \"song_popularity\",\n        }\n    )\n)\n\n\nWritting function to clean titles (Album & Track)\n\n\nCode\ndef clean_title(title: str):\n    # Remove everything in parentheses\n    title = re.sub(r\"\\(.*\\)\", \"\", title)\n    # Remove everything in brackets\n    title = re.sub(r\"\\[.*\\]\", \"\", title)\n    # Remove everything after a dash\n    title = re.sub(r\"^(.*?) -.*$\", r\"\\1\", title)\n    # Remove non-ASCII characters\n    title = re.sub(r\"[^\\x00-\\x7F]+\", \"\", title)\n    # Remove after colon\n    title = re.sub(r\"^(.*?) :.*$\", r\"\\1\", title)\n    # Strip leading and trailing whitespace\n    title = title.strip()\n\n    return title\n\n\nConverting Album Images to JSON Strings\n\n\nCode\ndef categorize_album_images(json_str):\n    try:\n        images = json.loads(json_str)\n        large = medium = small = {}\n        for img in images:\n            if img[\"height\"] == 640:\n                large = img\n            elif img[\"height\"] == 300:\n                medium = img\n            elif img[\"height\"] == 64:\n                small = img\n        return json.dumps(large), json.dumps(medium), json.dumps(small)\n    except json.JSONDecodeError:\n        return \"{}\", \"{}\", \"{}\"\n\n\n\ntrack_df[\"image_lg\"], track_df[\"image_md\"], track_df[\"image_sm\"] = zip(\n    *track_df.album_images.apply(categorize_album_images)\n)\n\nCleaning Album Dates\n\n\nCode\ndef categorize_decade(year):\n    if year &lt; 1950:\n        return \"Oldie\"\n    else:\n        return str(year)[2] + \"0s\"\n\n\n\ntrack_df[\"album_release_year\"] = track_df.apply(\n    lambda row: (\n        row[\"album_release_date\"][:4]\n        if row[\"album_release_date_precision\"] in [\"day\", \"month\", \"year\"]\n        else None\n    ),\n    axis=1,\n).astype(int)\n\n\ntrack_df[\"album_decade\"] = (\n    track_df[\"album_release_year\"].astype(int).apply(categorize_decade)\n)",
    "crumbs": [
      "Clean History"
    ]
  },
  {
    "objectID": "clean_data.html#clean-artist-data",
    "href": "clean_data.html#clean-artist-data",
    "title": "Clean History",
    "section": "Clean Artist Data",
    "text": "Clean Artist Data\n\nartist_df[artist_df.columns[artist_df.columns != \"images\"]] = artist_df[\n    artist_df.columns[artist_df.columns != \"images\"]\n].convert_dtypes()\n\nConvert Artist Images\n\n\nCode\ndef categorrize_img_size(json_str):\n    try:\n        images = json.loads(json_str)\n        xl = lg = md = sm = {}\n        for img in images:\n            if img[\"height\"] &gt; 800:\n                xl = img\n            elif img[\"height\"] &gt; 525:\n                lg = img\n            elif img[\"height\"] &gt; 180:\n                md = img\n            else:\n                sm = img\n        return json.dumps(xl), json.dumps(lg), json.dumps(md), json.dumps(sm)\n    except json.JSONDecodeError:\n        return \"{}\", \"{}\", \"{}\", \"{}\"\n\n\n\n(\n    artist_df[\"image_xl\"],\n    artist_df[\"image_lg\"],\n    artist_df[\"image_md\"],\n    artist_df[\"image_sm\"],\n) = zip(*artist_df.images.apply(categorrize_img_size))",
    "crumbs": [
      "Clean History"
    ]
  },
  {
    "objectID": "pull_history.html",
    "href": "pull_history.html",
    "title": "Pull Spotify History",
    "section": "",
    "text": "def get_spotipy_obj():\n    load_dotenv()\n    return spotipy.Spotify(auth_manager=SpotifyClientCredentials())",
    "crumbs": [
      "Pull Spotify History"
    ]
  },
  {
    "objectID": "pull_history.html#extract-streaming-history",
    "href": "pull_history.html#extract-streaming-history",
    "title": "Pull Spotify History",
    "section": "Extract Streaming History",
    "text": "Extract Streaming History\n\nConverting History JSON Files into Pandas DF\n\nSpotify provides a user’s history in a series of JSON Files. Some years have multiple files. I wrote a simple function to consolidate this history into a Dict with each year as the key\n\nstreaming_history = extract_streaming_history(Path(\"streaming_history\"))\n\nFor this excercise I’m going to only include music from my history that I’ve considered ‘played’. To do so I’ll filter the data here instead of adding a column in my Database that differentiates between played & unplayed.\nIn a real-life scenerio I’m more hesitant to throw away information but I didn’t intend to look at unplayed tracks and it wouldn’t have been wasted space on my db :)\nGonna use a cutoff of 70% played\n\nclean_history = clean_streaming_history(streaming_history, 0.7)",
    "crumbs": [
      "Pull Spotify History"
    ]
  },
  {
    "objectID": "pull_history.html#exploring-spotify-api-data",
    "href": "pull_history.html#exploring-spotify-api-data",
    "title": "Pull Spotify History",
    "section": "Exploring Spotify API Data",
    "text": "Exploring Spotify API Data\n\nFinding metadata that will enrich Spotify History\n\n\nsp = get_spotipy_obj()\n\n\nGenres\n\nStandardizing Genres\n\nSpotify provides genres at the Artist level and these genres can be all over the place. Let’s take a look at some examples\n\nJay-Z\n\n\njay = sp.artist(\"3nFkdlSjzX9mRTtwJOzDYB\")\n\n\njay[\"genres\"]\n\n['east coast hip hop', 'gangster rap', 'hip hop', 'pop rap', 'rap']\n\n\nJay-z is associated with 5 genres! When I think about Jay-Z I think East Coast Hip Hip but should that be his main genre?\nI have 2 things 2 consider here:\n\nHow to bucket artist into broad groups (rappers vs. rock stars)\nAnd how to bucket them into the sub-genres that I associate with them (east coast hip hop vs. west coast hip hop)\n\nLet’s take a look at 2 more examples:\n\nPink Floyd\n\n\npink = sp.artist(\"0k17h0D3J5VfsdmQ1iZtE9\")\n\n\npink[\"genres\"]\n\n['album rock',\n 'art rock',\n 'classic rock',\n 'progressive rock',\n 'psychedelic rock',\n 'rock',\n 'symphonic rock']\n\n\n\nKhruangbin\n\n\nkhruangbin = sp.artist(\"2mVVjNmdjXZZDvhgQWiakk\")\n\n\nkhruangbin[\"genres\"]\n\n['indie soul', 'neo-psychedelic']\n\n\nIn the case of Pink Floyd the genres that I want to associate with them are in the Spotify Response (Rock and Classic Rock). However, Khruangbin is a completly different story, I think they should be Indie.\nWhat I noticed looking through the data is that certain genres–like rap–came through well in the Spotify data while others–like indie–did not. My goal is paint a picture of my spotify history as I see it. If certain genre’s aren’t being mapped how I envision it’s going to mess with the visualizations.\nIn an ideal world I would have created a AI model or something similar to map the genres programmatically. However, I encountered this issue early in the development process. Perfection is the enemy of progress. My goal is to make a website that displays my data. Not to build an AI model :)\n\ngenre_mapping = pd.read_csv(\"genre_matching.csv\")\n\nSince I didn’t want to go through all the genres (there are ≈ 1800) I went through top 300 or so and wrote a regex to match others based on certain keywords\n\n\nCode\ndef consolidate_main_genre(genre: str):\n    if re.search(r\"\\brap\\b\", genre) or re.search(r\"\\bhip hop\\b\", genre):\n        return \"rap\"\n    elif re.search(r\"\\brock\\b\", genre):\n        return \"rock\"\n    elif re.search(r\"\\bsoul\\b\", genre):\n        return \"soul\"\n    elif re.search(r\"\\bpop\\b\", genre):\n        return \"pop\"\n    elif re.search(r\"\\bcountry\\b\", genre):\n        return \"country\"\n    elif re.search(\n        r\"\\bjazz\\b|\\binstrumental\\b|\\bblues\\b|\\bclassical\\b|\\blo-fi\\b|\\blofi\\b|\\bambient\\b\",\n        genre,\n    ):\n        return \"focus\"\n\n\n\npossible_genres = genre_mapping[genre_mapping.genres.isin(jay[\"genres\"])]\n\n\npossible_genres\n\n\n\n\n\n\n\n\n\ngenres\nmain_genre\nsecondary_genre\nhours_played\n\n\n\n\n0\nrap\nrap\nNaN\n4187.657624\n\n\n1\nhip hop\nrap\nNaN\n3636.079708\n\n\n3\npop rap\nrap\nNaN\n1747.090661\n\n\n8\ngangster rap\nrap\nNaN\n732.280244\n\n\n13\neast coast hip hop\nrap\neast coast hip hop\n617.484491\n\n\n\n\n\n\n\n\n\nPutting it all together\n\n\n\nCode\ndef consolidate_genres(genres: List[str]) -&gt; Dict:\n    possible_genres = genre_mapping[genre_mapping.genres.isin(genres)]\n    main_genre = \"\"\n    secondary_genre = \"\"\n    if possible_genres.shape[0] &gt; 0:\n        if possible_genres[\"main_genre\"].dropna().shape[0] &gt; 0:\n            main_genre = possible_genres[\"main_genre\"].dropna().iloc[0]\n        else:\n            main_genre = consolidate_main_genre(\n                possible_genres[\"genres\"].dropna().iloc[0]\n            )\n\n        if possible_genres[\"secondary_genre\"].dropna().shape[0] &gt; 0:\n            secondary_genre = possible_genres[\"secondary_genre\"].dropna().iloc[0]\n    return {\n        \"main_genre\": main_genre,\n        \"secondary_genre\": secondary_genre,\n        \"genres\": \";;\".join(genres),\n    }\n\n\n\nconsolidate_genres(jay[\"genres\"])\n\n{'main_genre': 'rap',\n 'secondary_genre': 'east coast hip hop',\n 'genres': 'east coast hip hop;;gangster rap;;hip hop;;pop rap;;rap'}\n\n\nWhile this is a good start, there’s still one scenerio that isn’t being accounted for:\n\nWhat if the artist API request doens’t return ANY genres?\n\nLet’s take a look at Santa Esmaralda\n\nsanta = sp.artist(\"0iGmfKLgK5eSMgHp8YgLnS\")\nsanta[\"genres\"]\n\n[]\n\n\nSanta doesn’t have any genres!!!  The solution here is simple. While Santa doesn’t have any genres himself, spotify provides a endpoint for related artist. I can find out the genres of his related artist and use this as a way to approximate Santa’s genre\n\nif not santa.get(\"genres\"):\n    related_artists = sp.artist_related_artists(\"0iGmfKLgK5eSMgHp8YgLnS\")\n    related_genres = {}\n    for art in related_artists[\"artists\"]:\n        if art.get(\"genres\"):\n            for genre in art[\"genres\"]:\n                if genre not in related_genres:\n                    related_genres[genre] = 0\n                related_genres[genre] += 1\n\n\n\n{'disco': 13,\n 'hi-nrg': 5,\n 'italo disco': 2,\n 'australian dance': 1,\n 'classic uk pop': 1,\n 'minneapolis sound': 1,\n 'synthpop': 1,\n 'diva house': 1,\n 'motown': 2,\n 'post-disco': 2,\n 'quiet storm': 1,\n 'deep disco': 1,\n 'vintage french electronic': 1}\n\n\nConsolidating the genres for Santa\n\nrelated_genres_list = list(related_genres.items())\n\n\nrelated_genres_list.sort(key=lambda x: x[1], reverse=True)\n\n\nrelated_genres_list = [x[0] for x in related_genres_list]\n\n\nconsolidate_genres(related_genres_list[:5])\n\n{'main_genre': 'soul',\n 'secondary_genre': 'dance',\n 'genres': 'disco;;hi-nrg;;italo disco;;motown;;post-disco'}\n\n\n\nProceduralizing\n\n\n\nCode\ndef get_artist_genres(artist) -&gt; Dict[str, int]:\n    if artist.get(\"genres\"):\n        consolidated_genres = consolidate_genres(artist[\"genres\"])\n        return {\n            \"genres\": consolidated_genres[\"genres\"],\n            \"main_genre\": (\n                consolidated_genres[\"main_genre\"]\n                if consolidated_genres[\"main_genre\"]\n                else consolidated_genres[\"genres\"][-1]\n            ),\n            \"secondary_genre\": (\n                consolidated_genres[\"secondary_genre\"]\n                if consolidated_genres[\"secondary_genre\"]\n                else consolidated_genres[\"genres\"].split(\";;\")[0]\n            ),\n        }\n    else:\n        sp = get_spotipy_obj()\n        related_artists = sp.artist_related_artists(artist[\"id\"])\n        related_genres = {}\n        for art in related_artists[\"artists\"]:\n            if art.get(\"genres\"):\n                for genre in art[\"genres\"]:\n                    if genre not in related_genres:\n                        related_genres[genre] = 0\n                    related_genres[genre] += 1\n        related_genres_list = list(related_genres.items())\n        related_genres_list.sort(key=lambda x: x[1], reverse=True)\n        related_genres_list = [x[0] for x in related_genres_list]\n        return consolidate_genres(related_genres_list[:5])\n\n\n\nget_artist_genres(jay)\n\n{'genres': 'east coast hip hop;;gangster rap;;hip hop;;pop rap;;rap',\n 'main_genre': 'rap',\n 'secondary_genre': 'east coast hip hop'}\n\n\n\n\nArtist\n\n\n['external_urls',\n 'followers',\n 'genres',\n 'href',\n 'id',\n 'images',\n 'name',\n 'popularity',\n 'type',\n 'uri']\n\n\nGetting metadata for main artist\n\n\nCode\ndef get_artist_data(artist_id: str, raw_artist_metadata: Dict = {}) -&gt; Dict:\n    sp = get_spotipy_obj()\n    artist = sp.artist(artist_id)\n    artist_genres = get_artist_genres(artist)\n    if artist[\"id\"] not in raw_artist_metadata:\n        raw_artist_metadata[artist[\"id\"]] = artist\n    return {\n        \"id\": artist[\"id\"],\n        \"name\": artist[\"name\"],\n        \"external_url\": artist[\"external_urls\"].get(\"spotify\"),\n        \"followers\": artist[\"followers\"][\"total\"],\n        \"genres\": artist_genres[\"genres\"],\n        \"href\": artist[\"href\"],\n        \"images\": json.dumps(artist[\"images\"]),\n        \"popularity\": artist[\"popularity\"],\n        \"type\": artist[\"type\"],\n        \"uri\": artist[\"uri\"],\n        \"main_genre\": artist_genres[\"main_genre\"],\n        \"secondary_genre\": artist_genres[\"secondary_genre\"],\n    }\n\n\nGetting all artist associated with a track\n\n\nCode\ndef get_track_artists(\n    track, artist_metadata: Dict = {}, raw_artist_metadata: Dict = {}\n) -&gt; Dict:\n    main_artist = None\n    artist_names = []\n    artist_ids = []\n    for i in range(len(track[\"artists\"])):\n        id = track[\"artists\"][i][\"id\"]\n        if artist_metadata.get(id):\n            artist = artist_metadata[id]\n        else:\n            artist = get_artist_data(id, raw_artist_metadata)\n            artist_metadata[id] = artist\n        if i == 0:\n            main_artist = artist\n            artist_names.append(artist[\"name\"])\n            artist_ids.append(artist[\"id\"])\n        else:\n            artist_names.append(artist[\"name\"])\n            artist_ids.append(artist[\"id\"])\n    return {\n        \"main_artist_id\": main_artist[\"id\"],\n        \"main_artist_name\": main_artist[\"name\"],\n        \"genres\": main_artist[\"genres\"],\n        \"main_genre\": main_artist[\"main_genre\"],\n        \"secondary_genre\": main_artist[\"secondary_genre\"],\n        \"main_artist_image\": main_artist[\"images\"],\n        \"main_artist_url\": main_artist[\"external_url\"],\n        \"main_artist_uri\": main_artist[\"uri\"],\n        \"artist_names\": \";;\".join(artist_names),\n        \"artist_ids\": \";;\".join(artist_ids),\n    }\n\n\n\n\nTrack Audio Features\n\nEnriching Tracks with Audio Features\n\nTo explore the Spotify Track Features I will be looking at metadata from 1 of my All-Time favorite songs:\n\n1 Train by A$AP Rocky (7AijU6oTPGmG64uWf63Qvc)\n\n\ntrack_ids = [\"7AijU6oTPGmG64uWf63Qvc\",]\ntracks = sp.tracks(track_ids)[\"tracks\"]\n\n\naudio_features = sp.audio_features(track_ids)\n\n\nTRACK_FEATURE_COLUMNS = [\n    \"danceability\",\n    \"energy\",\n    \"key\",\n    \"loudness\",\n    \"mode\",\n    \"speechiness\",\n    \"acousticness\",\n    \"instrumentalness\",\n    \"liveness\",\n    \"valence\",\n    \"tempo\",\n    \"analysis_url\",\n    \"time_signature\",\n]\n\n\ndef get_track_features(track_features: Dict, raw_audio_features: Dict = {}) -&gt; Dict:\n    if track_features[\"id\"] not in raw_audio_features:\n        raw_audio_features[track_features[\"id\"]] = track_features\n    return {k: track_features[k] for k in TRACK_FEATURE_COLUMNS}\n\n\ntrain_1_features = get_track_features(audio_features[current_track], raw_audio_features)\n\n\n\n{'danceability': 0.622,\n 'energy': 0.872,\n 'key': 2,\n 'loudness': -3.403,\n 'mode': 1,\n 'speechiness': 0.332,\n 'acousticness': 0.349,\n 'instrumentalness': 0,\n 'liveness': 0.695,\n 'valence': 0.768,\n 'tempo': 83.568,\n 'analysis_url': 'https://api.spotify.com/v1/audio-analysis/7AijU6oTPGmG64uWf63Qvc',\n 'time_signature': 4}\n\n\n\n\nAlbum Metadata\n\nKey Data Points: Label, Popularity, Album Tracks, Release Date\n\n\n\n['album_type',\n 'artists',\n 'available_markets',\n 'external_urls',\n 'href',\n 'id',\n 'images',\n 'name',\n 'release_date',\n 'release_date_precision',\n 'total_tracks',\n 'type',\n 'uri']\n\n\nSince I don’t want all the metadata associated with the album, I’m going to extract only the metadata I want\n\n\nCode\ndef get_album_data(track, album_metadata: Dict[str, Dict]):\n    if track[\"album\"][\"id\"] in album_metadata:\n        return album_metadata[track[\"album\"][\"id\"]]\n    album = {\n        \"name\": track[\"album\"][\"name\"],\n        \"id\": track[\"album\"][\"id\"],\n        \"artist\": \";;\".join([artist[\"name\"] for artist in track[\"album\"][\"artists\"]]),\n        \"artist_id\": \";;\".join([artist[\"id\"] for artist in track[\"album\"][\"artists\"]]),\n        \"external_url\": track[\"album\"][\"external_urls\"].get(\"spotify\"),\n        \"href\": track[\"album\"][\"href\"],\n        \"images\": json.dumps(track[\"album\"][\"images\"]),\n        \"release_date\": track[\"album\"][\"release_date\"],\n        \"release_date_precision\": track[\"album\"][\"release_date_precision\"],\n        \"total_tracks\": track[\"album\"][\"total_tracks\"],\n        \"type\": track[\"album\"][\"type\"],\n        \"uri\": track[\"album\"][\"uri\"],\n    }\n    album_metadata[album[\"id\"]] = album\n    return album\n\n\n\ntrain_1_album = get_album_data(train_1, album_metadata)\n\n\ntrain_1_album\n\n{'name': 'LONG.LIVE.A$AP (Deluxe Version)',\n 'id': '1E1eyI5uGllppJZCxNoF9w',\n 'artist': 'A$AP Rocky',\n 'artist_id': '13ubrt8QOOCPljQ2FL1Kca',\n 'external_url': 'https://open.spotify.com/album/1E1eyI5uGllppJZCxNoF9w',\n 'href': 'https://api.spotify.com/v1/albums/1E1eyI5uGllppJZCxNoF9w',\n 'images': '[{\"height\": 640, \"url\": \"https://i.scdn.co/image/ab67616d0000b2733265ed162fa2dd5ec6434ee4\", \"width\": 640}, {\"height\": 300, \"url\": \"https://i.scdn.co/image/ab67616d00001e023265ed162fa2dd5ec6434ee4\", \"width\": 300}, {\"height\": 64, \"url\": \"https://i.scdn.co/image/ab67616d000048513265ed162fa2dd5ec6434ee4\", \"width\": 64}]',\n 'release_date': '2013-01-11',\n 'release_date_precision': 'day',\n 'total_tracks': 16,\n 'type': 'album',\n 'uri': 'spotify:album:1E1eyI5uGllppJZCxNoF9w'}\n\n\n\n\nTrack\n\nPutting it all together\n\nWriting a funciton to get track data\n\n\nCode\ndef get_track_data(\n    track,\n    artist_metadata: Optional[Dict] = None,\n    raw_artist_metadata: Optional[Dict] = None,\n    audio_features: Optional[Dict] = None,\n    album_metadata: Optional[Dict] = {},\n) -&gt; Dict:\n    album = get_album_data(track, album_metadata)\n    artists = get_track_artists(\n        track, artist_metadata=artist_metadata, raw_artist_metadata=raw_artist_metadata\n    )\n    if not audio_features:\n        audio_features = {k: None for k in TRACK_FEATURE_COLUMNS}\n    return {\n        \"id\": track[\"id\"],\n        \"name\": track[\"name\"],\n        \"artist\": artists[\"main_artist_name\"],\n        \"album\": album[\"name\"],\n        \"album_id\": album[\"id\"],\n        \"album_release_date\": album[\"release_date\"],\n        \"album_release_date_precision\": album[\"release_date_precision\"],\n        \"album_type\": album[\"type\"],\n        \"album_uri\": album[\"uri\"],\n        \"album_external_url\": album[\"external_url\"],\n        \"album_href\": album[\"href\"],\n        \"album_images\": album[\"images\"],\n        \"artist_id\": artists[\"main_artist_id\"],\n        \"artist_names\": artists[\"artist_names\"],\n        \"artist_ids\": artists[\"artist_ids\"],\n        \"artist_genres\": artists[\"genres\"],\n        \"artist_main_genre\": artists[\"main_genre\"],\n        \"artist_secondary_genre\": artists[\"secondary_genre\"],\n        \"artist_image\": artists[\"main_artist_image\"],\n        \"main_artist_url\": artists[\"main_artist_url\"],\n        \"main_artist_uri\": artists[\"main_artist_uri\"],\n        \"danceability\": audio_features[\"danceability\"],\n        \"energy\": audio_features[\"energy\"],\n        \"key\": audio_features[\"key\"],\n        \"loudness\": audio_features[\"loudness\"],\n        \"mode\": audio_features[\"mode\"],\n        \"speechiness\": audio_features[\"speechiness\"],\n        \"acousticness\": audio_features[\"acousticness\"],\n        \"instrumentalness\": audio_features[\"instrumentalness\"],\n        \"liveness\": audio_features[\"liveness\"],\n        \"valence\": audio_features[\"valence\"],\n        \"tempo\": audio_features[\"tempo\"],\n        \"analysis_url\": audio_features[\"analysis_url\"],\n        \"time_signature\": audio_features[\"time_signature\"],\n    }",
    "crumbs": [
      "Pull Spotify History"
    ]
  },
  {
    "objectID": "pull_history.html#writing-batch-funcs",
    "href": "pull_history.html#writing-batch-funcs",
    "title": "Pull Spotify History",
    "section": "Writing Batch Funcs",
    "text": "Writing Batch Funcs\n\nsample_ids = clean_history.track_id.unique()[:200]\n\nWriting custom function to get multiple tracks at once   The spotipy lib seems to re-call the Spotify API immediatly after getting a ‘retry-after’ messages which Spotify doesn’t seem to appreciate. Instead I wait for 5 minutes :)\n\n\nCode\ndef get_multiple_tracks(track_ids: List) -&gt; List[Dict]:\n    def wait_for_rate_limit(response: requests.Response) -&gt; None:\n        print()\n        print(\"-----------------\")\n        print(\"Waiting for\", response.headers.get(\"retry-after\"), \"seconds\")\n        time.sleep(int(response.headers.get(\"retry-after\")) + 300)\n\n    auth_manager = SpotifyClientCredentials()\n    track_ids = \",\".join(track_ids)\n    url = f\"https://api.spotify.com/v1/tracks?ids={track_ids}\"\n    headers = {\n        \"Authorization\": f\"Bearer {auth_manager.get_access_token(as_dict=False)}\"\n    }\n    response = requests.get(url, headers=headers)\n\n    if response.headers.get(\"retry-after\"):\n        wait_for_rate_limit(response)\n        response = requests.get(url, headers=headers)\n\n    return response.json()\n\n\nPutting everything together   The following function will take a list of track ids and return a DataFrame with all the metadata for the tracks. To avoid rate limiting, the it’ll will puase for 200 seconds every 1000 ids and respect retry-after messages #IJUSTNEEDSOMESPACE\n\n\nCode\ndef enrich_spotify_data(\n    track_ids: List[str],\n    track_metadata: Dict = {},\n    artist_metadata: Dict = {},\n    album_metadata: Dict = {},\n    audio_features: Dict = {},\n    raw_track_metadata: Dict = {},\n    raw_artist_metadata: Dict = {},\n) -&gt; Dict:\n    sp = get_spotipy_obj()\n    BATCH_SIZE = 50\n    batch = []\n\n    for i in range(len(track_ids)):\n        track_id = track_ids[i]\n\n        if track_id in track_metadata:\n            continue\n\n        batch.append(track_id)\n\n        if len(batch) == BATCH_SIZE or i == len(track_ids) - 1:\n            tracks = sp.tracks(batch)[\"tracks\"]\n            audio_features_batch = sp.audio_features(batch)\n\n            for features in audio_features_batch:\n                if features:\n                    if features[\"id\"] not in audio_features:\n                        audio_features[features[\"id\"]] = features\n\n            for track in tracks:\n                if track[\"id\"] not in raw_track_metadata:\n                    raw_track_metadata[track[\"id\"]] = track\n                track_metadata[track[\"id\"]] = get_track_data(\n                    track,\n                    artist_metadata=artist_metadata,\n                    raw_artist_metadata=raw_artist_metadata,\n                    audio_features=(\n                        audio_features.get(track[\"id\"])\n                        if audio_features.get(track[\"id\"])\n                        else {k: None for k in TRACK_FEATURE_COLUMNS}\n                    ),\n                    album_metadata=album_metadata,\n                )\n\n            batch = []\n            if ((i + 1) % 1000) == 0:\n                print(\"Track\", i + 1, \"complete\")\n            time.sleep(200)\n\n    return {\n        \"track_metadata\": track_metadata,\n        \"artist_metadata\": artist_metadata,\n        \"album_metadata\": album_metadata,\n        \"audio_features\": audio_features,\n        \"raw_track_metadata\": raw_track_metadata,\n        \"raw_artist_metadata\": raw_artist_metadata,\n    }",
    "crumbs": [
      "Pull Spotify History"
    ]
  },
  {
    "objectID": "pull_history.html#enriching-data",
    "href": "pull_history.html#enriching-data",
    "title": "Pull Spotify History",
    "section": "Enriching Data",
    "text": "Enriching Data\n\ntrack_ids = clean_history.track_id.unique()\n\n\nfor i in range(0, len(track_ids), 1000):\n    print(\"Processing tracks\", i, \"to\", i + 1000)\n    end = min(i + 1000, len(track_ids))\n    data = enrich_spotify_data(\n        track_ids[i:end],\n        track_metadata=track_metadata,\n        artist_metadata=artist_metadata,\n        album_metadata=album_metadata,\n        audio_features=audio_features,\n        raw_track_metadata=raw_track_metadata,\n        raw_artist_metadata=raw_artist_metadata,\n    )\n    track_metadata = data[\"track_metadata\"]\n    artist_metadata = data[\"artist_metadata\"]\n    album_metadata = data[\"album_metadata\"]\n    audio_features = data[\"audio_features\"]\n    raw_track_metadata = data[\"raw_track_metadata\"]\n    raw_artist_metadata = data[\"raw_artist_metadata\"]",
    "crumbs": [
      "Pull Spotify History"
    ]
  },
  {
    "objectID": "seed_sql.html",
    "href": "seed_sql.html",
    "title": "Seed Database",
    "section": "",
    "text": "import os\nimport pickle\nimport pandas as pd\n\nfrom pathlib import Path\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.sql import text\nfrom spotify_etl.core import *\nfrom dotenv import load_dotenv\ncomplete_history = get_pickle_data(Path(\"data/complete_history.pkl\"))\ntrack_df = get_pickle_data(Path(\"data/track_df.pkl\"))\nartist_df = get_pickle_data(Path(\"data/artist_df.pkl\"))\nengine = create_engine(POSTGRES_URL)",
    "crumbs": [
      "Seed Database"
    ]
  },
  {
    "objectID": "seed_sql.html#creating-tables",
    "href": "seed_sql.html#creating-tables",
    "title": "Seed Database",
    "section": "Creating Tables",
    "text": "Creating Tables\n\nCreating Tables if not exists\n\nTo optimize query speed I’ll be creating indexes on frequently filtered data\n\ndef create_index(table, column):\n    return text(\n        f\"CREATE INDEX IF NOT EXISTS idx_{table}_{column} ON {table}({column});\"\n    )\n\n\nArtist Metadata\n\n\n\nCode\nwith engine.connect() as conn:\n    conn.execute(\n        text(\n            f\"\"\"\n    CREATE TABLE IF NOT EXISTS artist_metadata (\n        \"artist_id\" text PRIMARY KEY UNIQUE,\n        \"artist\" text,\n        \"main_genre\" text,\n        \"secondary_genre\" text,\n        \"genres\" text,\n        \"popularity\" integer,\n        \"followers\" integer,\n        \"image_xl\" JSONB,\n        \"image_lg\" JSONB,\n        \"image_md\" JSONB,\n        \"image_sm\" JSONB,\n        \"images\" JSONB,\n        \"type\" text,\n        \"uri\" text,\n        \"external_url\" text,\n        \"href\" text       \n    );\n    \"\"\"\n        )\n    )\n    conn.commit()\n    conn.execute(create_index(\"artist_metadata\", \"main_genre\"))\n    conn.execute(create_index(\"artist_metadata\", \"secondary_genre\"))\n    conn.commit()\n\n\n\nTrack Metadata\n\n\n\nCode\nwith engine.connect() as conn:\n    conn.execute(\n        text(\n            f\"\"\"\n    CREATE TABLE IF NOT EXISTS track_metadata (\n    \"track_id\" TEXT PRIMARY KEY UNIQUE,\n    \"song\" TEXT,\n    \"album\" TEXT,\n    \"explicit\" BOOLEAN,\n    \"song_popularity\" INTEGER,\n    \"main_artist_id\" TEXT  REFERENCES artist_metadata(artist_id),\n    \"artist_names\" TEXT,\n    \"artist_ids\" TEXT,\n    \"album_id\" TEXT,\n    \"album_release_date\" TEXT,\n    \"album_release_date_precision\" TEXT,\n    \"album_external_url\" TEXT,\n    \"album_href\" TEXT,\n    \"album_images\" JSONB,\n    \"album_type\" TEXT,\n    \"album_uri\" TEXT,\n    \"danceability\" FLOAT,\n    \"energy\" FLOAT,\n    \"key\" INTEGER,\n    \"loudness\" FLOAT,\n    \"mode\" INTEGER,\n    \"speechiness\" FLOAT,\n    \"acousticness\" FLOAT,\n    \"instrumentalness\" FLOAT,\n    \"liveness\" FLOAT,\n    \"valence\" FLOAT,\n    \"tempo\" FLOAT,\n    \"duration_ms\" INTEGER,\n    \"time_signature\" INTEGER,\n    \"album_release_year\" INTEGER,\n    \"album_decade\" TEXT,\n    \"image_lg\" JSONB,\n    \"image_md\" JSONB,\n    \"image_sm\" JSONB,\n    \"analysis_url\" TEXT\n    );\n    \"\"\"\n        )\n    )\n    conn.commit()\n    conn.execute(create_index(\"track_metadata\", \"main_artist_id\"))\n    conn.execute(create_index(\"track_metadata\", \"album_id\"))\n    conn.execute(create_index(\"track_metadata\", \"album_release_year\"))\n    conn.execute(create_index(\"track_metadata\", \"album_decade\"))\n    conn.commit()\n\n\n\nSpotify History (Partition)\n\nOne of the main goals of this project is to analyze my listening history over time. With this in mind, I decided to partition the spotify history table by year to optimize for queries over specific periods of time. This approach allows queries to quickly access relevant data by narrowing down the search to specific partitions, reducing the need to scan the entire table. It’s especially effective for managing and analyzing large volumes of data over defined time periods, making the system more responsive and scalable.\nIn addition to greatly enhancing query performance this method also simplifies maintenance tasks, such as data archiving or cleanup, by isolating data into manageable chunks.\n\n\nCode\nwith engine.connect() as conn:\n    conn.execute(\n        text(\n            f\"\"\"\n    -- Create the history table\n    CREATE TABLE IF NOT EXISTS spotify_history (\n        \"id\" INTEGER NOT NULL,\n        \"ts\" TIMESTAMP NOT NULL,\n        \"username\" INTEGER,\n        \"platform\" text,\n        \"ms_played\" INTEGER,\n        \"conn_country\" text,\n        \"ip_addr_decrypted\" text,\n        \"user_agent_decrypted\" text,\n        \"song\" text,\n        \"artist\" text,\n        \"album\" text,\n        \"URI\" text,\n        \"reason_start\" text,\n        \"reason_end\" text,\n        \"shuffle\" BOOLEAN,\n        \"skipped\" text,\n        \"offline\" text,\n        \"offline_timestamp\" FLOAT,\n        \"incognito_mode\" BOOLEAN,\n        \"month\" smallint,\n        \"year\" smallint,\n        \"track_id\" text REFERENCES track_metadata(track_id),\n        \"main_artist_id\" text REFERENCES artist_metadata(artist_id),\n        \"percent_played\" FLOAT\n    )  \n    PARTITION BY RANGE (ts)\n    ;\n                      \n\n    -- Create a sequence for the primary key\n    CREATE SEQUENCE IF NOT EXISTS spotify_history_id_seq;\n                      \n\n    -- Create a function to create yearly partitions        \n    CREATE OR REPLACE FUNCTION create_yearly_partitions(start_year INT, end_year INT)\n    RETURNS VOID AS $$\n    DECLARE\n        current_year INT := start_year;\n        partition_name TEXT;\n        index_name TEXT;\n    BEGIN\n        WHILE current_year &lt;= end_year LOOP\n            partition_name := 'spotify_history_y' || current_year;\n            index_name := partition_name || '_id_idx';\n\n            -- Create partition table using dollar-quoting for the SQL string\n            EXECUTE format($f$\n                CREATE TABLE IF NOT EXISTS %I\n                PARTITION OF spotify_history FOR VALUES FROM (%L) TO (%L);\n            $f$, partition_name, current_year || '-01-01', (current_year + 1) || '-01-01');\n\n            -- Create unique index on the partition table\n            EXECUTE format($f$\n                CREATE UNIQUE INDEX IF NOT EXISTS %I\n                ON %I (id);\n            $f$, index_name, partition_name);\n    \n            current_year := current_year + 1;\n        END LOOP;\n     END;\n     $$ LANGUAGE plpgsql;\n                      \n    -- Add the yearly partitions\n    SELECT create_yearly_partitions({complete_history.year.min()}, EXTRACT(YEAR FROM CURRENT_DATE)::INT);\n\n    -- Create a function to automatically insert new rows into the correct partition\n    CREATE OR REPLACE FUNCTION spotify_history_auto_id()\n    RETURNS TRIGGER AS $$\n    BEGIN\n        -- Check if the new row's id is NULL or not provided and automatically assign a value from the sequence\n        IF NEW.id IS NULL THEN\n            NEW.id := nextval('spotify_history_id_seq');\n        END IF;\n        RETURN NEW;\n    END;\n    $$ LANGUAGE plpgsql;\n\n    -- Trigger to automatically insert new rows into the correct partition\n    CREATE OR REPLACE TRIGGER spotify_history_before_insert\n    BEFORE INSERT ON spotify_history\n    FOR EACH ROW EXECUTE FUNCTION spotify_history_auto_id();\n    \"\"\"\n        )\n    )\n    conn.commit()\n    conn.execute(create_index(\"spotify_history\", \"ts\"))\n    conn.execute(create_index(\"spotify_history\", \"main_artist_id\"))\n    conn.execute(create_index(\"spotify_history\", \"track_id\"))\n    conn.execute(create_index(\"spotify_history\", \"year\"))\n    conn.execute(create_index(\"spotify_history\", \"month\"))\n    conn.execute(create_index(\"spotify_history\", \"album\"))\n    conn.commit()\n\n\n\nArtist Tracks\n\n\n\nCode\nwith engine.connect() as conn:\n    conn.execute(\n        text(\n            f\"\"\"\n    CREATE TABLE IF NOT EXISTS artist_tracks (\n        id SERIAL PRIMARY KEY UNIQUE,\n        \"track_id\" TEXT REFERENCES track_metadata(track_id),\n        \"artist_id\" TEXT REFERENCES artist_metadata(artist_id),\n        \"is_main_artist\" BOOLEAN\n    );\n    \"\"\"\n        )\n    )\n    conn.commit()\n    conn.execute(create_index(\"artist_tracks\", \"artist_id\"))\n    conn.execute(create_index(\"artist_tracks\", \"track_id\"))\n    conn.execute(create_index(\"artist_tracks\", \"is_main_artist\"))\n    conn.commit()",
    "crumbs": [
      "Seed Database"
    ]
  },
  {
    "objectID": "seed_sql.html#getting-data-ready",
    "href": "seed_sql.html#getting-data-ready",
    "title": "Seed Database",
    "section": "Getting Data Ready",
    "text": "Getting Data Ready\n\n\nCode\nartist_metadata = artist_df[\n    [\n        \"artist_id\",\n        \"artist\",\n        \"main_genre\",\n        \"secondary_genre\",\n        \"genres\",\n        \"popularity\",\n        \"followers\",\n        \"image_xl\",\n        \"image_lg\",\n        \"image_md\",\n        \"image_sm\",\n        \"images\",\n        \"type\",\n        \"uri\",\n        \"external_url\",\n        \"href\",\n    ]\n].copy()\n\ntrack_metadata = track_df[\n    [\n        \"track_id\",\n        \"song\",\n        \"album\",\n        \"explicit\",\n        \"song_popularity\",\n        \"main_artist_id\",\n        \"artist_names\",\n        \"artist_ids\",\n        \"album_id\",\n        \"album_release_date\",\n        \"album_release_date_precision\",\n        \"album_external_url\",\n        \"album_href\",\n        \"album_images\",\n        \"album_type\",\n        \"album_uri\",\n        \"danceability\",\n        \"energy\",\n        \"key\",\n        \"loudness\",\n        \"mode\",\n        \"speechiness\",\n        \"acousticness\",\n        \"instrumentalness\",\n        \"liveness\",\n        \"valence\",\n        \"tempo\",\n        \"duration_ms\",\n        \"time_signature\",\n        \"album_release_year\",\n        \"album_decade\",\n        \"image_lg\",\n        \"image_md\",\n        \"image_sm\",\n        \"analysis_url\",\n    ]\n].copy()\n\nspotify_history = complete_history[\n    [\n        \"ts\",\n        \"username\",\n        \"platform\",\n        \"ms_played\",\n        \"conn_country\",\n        \"ip_addr_decrypted\",\n        \"user_agent_decrypted\",\n        \"song\",\n        \"artist\",\n        \"album\",\n        \"URI\",\n        \"reason_start\",\n        \"reason_end\",\n        \"shuffle\",\n        \"skipped\",\n        \"offline\",\n        \"offline_timestamp\",\n        \"incognito_mode\",\n        \"month\",\n        \"year\",\n        \"track_id\",\n        \"main_artist_id\",\n        \"percent_played\",\n    ]\n].copy()\n\n\nCreating a function to get the artist track data\n\n\nCode\ndef create_artist_track(trck_metadata_df):\n    artist_tracks = (\n        track_df[[\"track_id\", \"artist_ids\", \"main_artist_id\"]]\n        .reset_index(drop=True)\n        .copy()\n    )\n\n    artist_tracks_exploded = artist_tracks.assign(\n        artist_id=artist_tracks[\"artist_ids\"].str.split(\";;\")\n    ).explode(\"artist_id\")\n\n    artist_tracks_exploded[\"is_main_artist\"] = (\n        artist_tracks_exploded[\"artist_id\"] == artist_tracks_exploded[\"main_artist_id\"]\n    )\n\n    final_df = artist_tracks_exploded[[\n        \"track_id\", \"artist_id\", \"is_main_artist\"]]\n\n    return final_df.reset_index(drop=True)\n\n\nartist_tracks = create_artist_track(track_df)",
    "crumbs": [
      "Seed Database"
    ]
  },
  {
    "objectID": "seed_sql.html#load-data",
    "href": "seed_sql.html#load-data",
    "title": "Seed Database",
    "section": "Load Data",
    "text": "Load Data\n\nIf it hasn’t already been loaded\n\nSince the goal of this project is to work with a snapshot of the data, we can check if there’s data in the tables before proceeding.\n\ndef insert_data(df, table):\n    with engine.connect() as connection:\n        result = connection.execute(\n            text(f\"SELECT COUNT(*) FROM {table}\"))\n        count = result.scalar()\n        if count == 0:\n            df.to_sql(table, connection, if_exists=\"append\", index=False)\n        else:\n            print(\"Table already has data, skipping insert\")\n\n\ninsert_data(artist_metadata, \"artist_metadata\")\n\nTable already has data, skipping insert\n\n\n\ninsert_data(track_metadata, \"track_metadata\")\n\nTable already has data, skipping insert\n\n\n\ninsert_data(spotify_history, \"spotify_history\")\n\nTable already has data, skipping insert\n\n\n\ninsert_data(artist_tracks, \"artist_tracks\")\n\nTable already has data, skipping insert",
    "crumbs": [
      "Seed Database"
    ]
  },
  {
    "objectID": "seed_sql.html#creating-materialized-view",
    "href": "seed_sql.html#creating-materialized-view",
    "title": "Seed Database",
    "section": "Creating Materialized View",
    "text": "Creating Materialized View\n\n… Making Dashboarding Easier :)\n\nSince the data is static and my goal is to build a dashboard I’ve chosen to write a materialized view. Using a materialized view is beneficial because it allows precomputing and storing complex joins and aggregations from the underlying data tables. This significantly enhances query performance when accessing the dashboard, as intensive computation is handled during the view’s refresh phase rather than at query time.\nSince the data is static, the materialized view doesn’t require frequent updates, making it an efficient way to provide quick access to processed data without extra load on the database during peak usage. This method is particularly effective for ensuring fast response times and improving scalability of the dashboard application.\n\nwith engine.connect() as conn:\n    conn.execute(\n        text(\n            f\"\"\" \n    CREATE MATERIALIZED VIEW IF NOT EXISTS spotify_data_overview AS\n    with timePlayed AS (\n    select\n        sh.id,\n        CAST(SUM(sh.ms_played) AS FLOAT) / (1000 * 60 * 60) as hours_played,\n        CAST(SUM(sh.ms_played) AS FLOAT) / (1000 * 60) as minutes_played\n    from \n        spotify_history as sh\n    group by sh.id\n)\n    SELECT\n        sh.id,\n        sh.ts,\n        tm.song,\n        am.artist,\n        tm.album,\n        am.main_genre,\n        am.secondary_genre,   \n        am.genres as genre_list,\n        tm.artist_names,\n        tm.artist_ids,\n        tm.image_lg as album_image_lg,\n        tm.image_md as album_image_md,\n        tm.image_sm as album_image_sm,\n        tm.album_images,\n        am.image_xl as artist_image_xl,\n        am.image_lg as artist_image_lg,\n        am.image_md as artist_image_md,\n        am.image_sm as artist_image_sm,\n        am.images as artist_images,\n        tm.track_id,\n        am.artist_id,\n        tm.album_id,\n        tm.explicit,\n        tm.song_popularity,\n        am.popularity AS artist_popularity,\n        tm.danceability,\n        tm.energy,\n        tm.key,\n        tm.loudness,\n        tm.mode,\n        tm.speechiness,\n        tm.acousticness,\n        tm.instrumentalness,\n        tm.liveness,\n        tm.valence,\n        tm.tempo,\n        tm.duration_ms,\n        tm.time_signature,\n        tm.album_release_date AS release_date,\n        tm.album_release_year,\n        tm.album_decade,   \n        DATE_TRUNC('month', sh.ts) as \"month\", -- Truncate the timestamp to the month\n        DATE_TRUNC('year', sh.ts) as \"year\", -- Truncate the timestamp to the year\n        CASE\n          WHEN am.main_genre ILIKE '% lo-fi' OR am.main_genre ILIKE 'lo-fi%' OR am.main_genre ILIKE '% lo-fi %' THEN 'Non-Rap'\n          WHEN am.main_genre ILIKE '% hip hop' OR am.main_genre ILIKE 'hip hop%' OR am.main_genre ILIKE '% hip hop %'\n              OR am.main_genre ILIKE '% rap' OR am.main_genre ILIKE 'rap%' OR am.main_genre ILIKE '% rap %' THEN 'Rap'\n          ELSE 'Non-Rap'\n        END AS genre_category,\n        sh.ms_played,\n        tp.minutes_played,\n        tp.hours_played,\n        DATE_TRUNC('day', sh.ts) as \"day\", -- Truncate the timestamp to the year\n        sh.reason_start,\n        sh.reason_end,\n        sh.shuffle,\n        CASE \n            WHEN tm.instrumentalness &gt; 0.5 THEN TRUE\n            ELSE FALSE\n        END AS is_instrumental\n    FROM spotify_history sh\n    JOIN track_metadata tm ON sh.track_id = tm.track_id\n    JOIN artist_metadata am ON sh.main_artist_id = am.artist_id\n    JOIN timePlayed tp ON sh.id = tp.id\n    \"\"\"\n        )\n    )\n    conn.commit()\n    conn.execute(create_index(\"spotify_data_overview\", \"artist_id\"))\n    conn.execute(create_index(\"spotify_data_overview\", \"track_id\"))\n    conn.execute(create_index(\"spotify_data_overview\", \"album_id\"))\n    conn.execute(create_index(\"spotify_data_overview\", \"year\"))\n    conn.execute(create_index(\"spotify_data_overview\", \"month\"))\n    conn.execute(create_index(\"spotify_data_overview\", \"song\"))\n    conn.execute(create_index(\"spotify_data_overview\", \"artist\"))\n    conn.execute(create_index(\"spotify_data_overview\", \"album\"))\n    conn.execute(create_index(\"spotify_data_overview\", \"main_genre\"))\n    conn.execute(create_index(\"spotify_data_overview\", \"secondary_genre\"))\n    conn.execute(create_index(\"spotify_data_overview\", \"genre_list\"))\n    conn.execute(create_index(\"spotify_data_overview\", \"artist_names\"))\n    conn.execute(create_index(\"spotify_data_overview\", \"ts\"))\n    conn.execute(create_index(\"spotify_data_overview\", \"genre_category\"))\n    conn.commit()",
    "crumbs": [
      "Seed Database"
    ]
  }
]